import { UnifiedAIOutput, AIPhase } from '../types';
import { PredictionServiceClient } from '@google-cloud/aiplatform';
import { GoogleGenerativeAI } from '@google/generative-ai';
import policy from '../providers/policy.google.json' with { type: 'json' };
import { vertexAIConfig } from '../vertexAIConfig';

export async function geminiCall(phase: AIPhase, prompt:any) : Promise<UnifiedAIOutput> {
  const t0 = Date.now();
  
  // Configuration Vertex AI centralis√©e - PRIORIT√â ABSOLUE
  console.log('üéØ Initialisation Vertex AI (mode production)...');
  
  const config = vertexAIConfig.getConfig();
  console.log('‚úÖ Configuration Vertex AI valid√©e:', {
    projectId: config.projectId,
    location: config.location,
    model: config.modelName,
    status: 'üöÄ PRODUCTION READY'
  });
  
  // VERTEX AI UNIQUEMENT - Plus de fallback
  console.log('üöÄ Initialisation Vertex AI (mode priorit√©)...');
  
  let clientConfig: any = {
    projectId,
    location
  };
  
  // Parse et validation des credentials Vertex AI
  let credentials: any;
  try {
    credentials = JSON.parse(credentialsJson!);
    clientConfig.credentials = credentials;
    console.log('‚úÖ Credentials Vertex AI valid√©s et charg√©s');
  } catch (credError) {
    console.error('‚ùå Erreur parsing credentials Vertex AI:', credError);
    throw new Error(`Format JSON des credentials Vertex AI invalide: ${credError.message}`);
  }
  
  const client = new PredictionServiceClient(clientConfig);
  
  const modelName = process.env.GEMINI_MODEL || 'gemini-1.5-flash';
  const endpoint = `projects/${projectId}/locations/${location}/publishers/google/models/${modelName}`;
  
  console.log(`üéØ Vertex AI Endpoint: ${endpoint}`);
  
  const instanceValue = {
    contents: [{ role: 'user', parts: [{ text: JSON.stringify(prompt) }]}]
  };
  
  const parameter = {
    candidateCount: 1,
    maxOutputTokens: 8192,
    temperature: 0.1,
    responseMimeType: 'application/json',
    topP: 0.95,
    topK: 40
  };
  
  const request = {
    endpoint,
    instances: [instanceValue],
    parameters: parameter,
  };
  
  console.log('üì° Envoi requ√™te Vertex AI (mode production)...');
  
  let text: string;
  try {
    const [response] = await client.predict(request);
    text = response.predictions?.[0]?.candidates?.[0]?.content?.parts?.[0]?.text || '';
    
    if (!text) {
      throw new Error('R√©ponse vide de Vertex AI');
    }
    
    console.log('‚úÖ R√©ponse Vertex AI re√ßue avec succ√®s');
    
  } catch (vertexError) {
    console.error('üö® ERREUR CRITIQUE VERTEX AI:', vertexError);
    throw new Error(`Vertex AI √©chou√©: ${vertexError.message}. V√©rifiez votre configuration Google Cloud.`);
  }

  let parsed:any;
  try { parsed = JSON.parse(text); } catch { parsed = { raw:text }; }

  const latency = Date.now() - t0;

  const out: UnifiedAIOutput = {
    phase,
    model_family: 'gemini',
    model_name: modelName,
    input_redacted: {}, // sera rempli par le logger apr√®s redaction
    output: parsed,
    quality: { latency_ms: latency },
    meta: {
      provider: 'vertex-ai',
      project_id: projectId,
      location: location,
      allow_training: !!policy.allow_training,
      provenance: 'vertex-ai-production',
      created_at: new Date().toISOString(),
      vertex_ai_priority: true
    }
  };
  return out;
}